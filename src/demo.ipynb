{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Demo for KI Seminar\n",
    "\n",
    "## Content to create\n",
    "\n",
    "- Podcast script\n",
    "- Presentation\n",
    "- Code Demo?\n",
    "\n",
    "## Sequence - Podcast Script\n",
    "\n",
    "- Ask for the topic\n",
    "- Figure out the requirements\n",
    "  - How long does it need to be (time wise)\n",
    "    - (google wpm talking speed)\n",
    "    - calculate the words to time with wpm talking speed\n",
    "  - Topics (How do they work?, ChatGPT vs open models, ...)\n",
    "- Gather information on the topic and requirements (google search or wikipedia)\n",
    "- output information\n",
    "  - maybe to file even?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting ideas / modifications\n",
    "\n",
    "- could generate an interesting topic inside the domain of large language models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "import wikipedia\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup chatgpt\n",
    "\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "llm = OpenAI(openai_api_key=openai_api_key, temperature=0.9)  # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the topic for which we want to create the podcast for\n",
    "T1 = 'Large Language Models'\n",
    "T2 = 'Time series analysis'\n",
    "T3 = 'Face aging'\n",
    "T4 = 'Colorize'\n",
    "T5 = 'Recommendation Systems'\n",
    "T6 = 'Bayesian modelling'\n",
    "T7 = 'Process Mining'\n",
    "T8 = 'Voice Recognition'\n",
    "T9 = 'Dialect in speech recognition'\n",
    "T10 = 'Transfer Learning in Speech Recognition'\n",
    "T11 = 'Auto Deep Learning'\n",
    "T12 = 'Automatic feature extraction'\n",
    "\n",
    "topic = T1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Gathering information from the lecture notes\n",
    "\n",
    "We can use ChatGPT to interpret the lecture slides which lists out the requirements for the podcast.\n",
    "By loading this document we can figure out:\n",
    "\n",
    "- the duration which the podcast should have (20 min)\n",
    "- How many words the use in the script for the podcast\n",
    "- Which topics should be covered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document loaders\n",
    "loader = TextLoader(file_path='../documents/VL1-1-processed-eng.txt', encoding='utf-8')\n",
    "document_content = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=600, chunk_overlap=0)\n",
    "split_content = text_splitter.split_documents(document_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings\n",
    "if os.path.isfile('../objects/embeddings.pkl'):\n",
    "    with open('../objects/embeddings.pkl', 'rb') as embeddings_file:\n",
    "        embeddings = pickle.load(embeddings_file)\n",
    "else:\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)  # type: ignore\n",
    "embeddings_search = Chroma.from_documents(split_content, embeddings)\n",
    "embeddings_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prompt template to get usable results\n",
    "prompt_template_text_document = \"\"\"\n",
    "Instruction:\n",
    "- Use the following pieces of context to answer the question at the end.\n",
    "- If you don't know the answer output: NULL\n",
    "- Just answer the question without providing any additional information\n",
    "\n",
    "Context:\n",
    "    {context}\n",
    "\n",
    "Question:\n",
    "    {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template_documents = PromptTemplate(template=prompt_template_text_document, input_variables=['context', 'question'])\n",
    "chain_type_kwargs = {'prompt': prompt_template_documents}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create retriever\n",
    "# usage with prompt templates see: https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html\n",
    "# to see the source documents set: return_source_documents=True\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=embeddings_search.as_retriever(), chain_type_kwargs=chain_type_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the duration of the podcast in minutes\n",
    "query_duration = 'Which time duration should the podcast have?'\n",
    "res_duration = qa.run(query_duration)\n",
    "res_duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This isn't used later but still an interesting application to use\n",
    "prompt_template_text_num_words = \"\"\"\n",
    "Instructions:\n",
    "  - if you are not sure make an estimate\n",
    "  - output just a number\n",
    "  - don't use any text in the answer like for example \"aproximately\" or \"words\"\n",
    "\n",
    "Context:\n",
    "  {context}\n",
    "\n",
    "Question:\n",
    "  How many words should I use in my podcast script to be able to talk the entire duration if a human speaks at 150 words per minute?\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt_template_num_words = PromptTemplate(template=prompt_template_text_num_words, input_variables=['context'])\n",
    "num_words_chain = LLMChain(llm=llm, prompt=prompt_template_num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ask chatgpt how many words to use for the podcast\n",
    "res_words = num_words_chain.run(context=res_duration)\n",
    "res_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_words(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Use the output prompt to match the number of words and convert it to a int value\n",
    "\n",
    "    :param text: the prompt the tells us the number of words to use\n",
    "    :returns: the number specified in the text or 1000 if no number could be found\n",
    "    \"\"\"\n",
    "    max_tokens = 2048\n",
    "    regex = r\"\\b(\\d+[,.]\\d+|\\d+)\\b\"\n",
    "    results: list[str] = re.findall(regex, text, re.MULTILINE)\n",
    "    if not results:\n",
    "        return max_tokens\n",
    "\n",
    "    no_comma = re.sub(r'[,]', '', results[-1])\n",
    "    float_result = float(no_comma)\n",
    "    suggestion = round(float_result)\n",
    "    return max_tokens if suggestion > max_tokens else suggestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the output from chatgpt to an integer\n",
    "num_words_to_use = get_num_words(res_words)\n",
    "num_words_to_use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for the topics which should be used in the podcast\n",
    "query_topics = f'Which topics should be covered in the podcast about {topic}?'\n",
    "res_topics = qa.run(query_topics)\n",
    "res_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the topics in a way to be interpretable\n",
    "formatted_topics = re.split(r'[,|\\n|?]', res_topics)\n",
    "formatted_topics = [topic.strip() for topic in formatted_topics if not re.search(r'^$', topic)]\n",
    "formatted_topics\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Doing research about the topics\n",
    "\n",
    "Now that we found out which requirements and topics we should use we can now do research regarding these.\n",
    "For this we can use a variety of tools (also langchain integrations), but here we chose to use the wikipedia api.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_wikipedia(topic: str):\n",
    "    \"\"\"\n",
    "    Ask wikipedia for the summary of the topic.\n",
    "    Note: results my be inaccurate!\n",
    "\n",
    "    :param topic: the topic to ask wikipedia for\n",
    "    :returns: the summary of the topic or an empty string if nothing was found\n",
    "    \"\"\"\n",
    "    time.sleep(0.3)\n",
    "    search = wikipedia.search(topic)\n",
    "    if not search:\n",
    "        return ''\n",
    "\n",
    "    try:\n",
    "        return wikipedia.summary(search[0], sentences=5)\n",
    "    except wikipedia.PageError:\n",
    "        return ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_research = '\\n'.join([ask_wikipedia(topic) for topic in formatted_topics])\n",
    "wiki_research\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate podcast script\n",
    "\n",
    "Now that we have done our research about the topic we can generate our podcast script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_text_script = \"\"\"\n",
    "Sub Topics:\n",
    "  {sub_topics}\n",
    "\n",
    "Context:\n",
    "  \\\"{context}\\\"\n",
    "\n",
    "Podcast Participants:\n",
    "  - Host\n",
    "  - Expert\n",
    "\n",
    "Previous Section of the Podcast Script:\n",
    "  \\\"{previous_section}\\\"\n",
    "\n",
    "Task:\n",
    "  - Your task is to write a podcast script about \\\"{topic}\\\".\n",
    "  - The Sub Topics refine the main topic and need to be addressed!\n",
    "  - Use your own knowledge and the one provided in Context if you think it fit the topic.\n",
    "  - Continue from the previous section and output the new content.\n",
    "  - If you think you are done output [END]\n",
    "\n",
    "\"\"\"\n",
    "prompt_template_podcast = PromptTemplate(template=prompt_template_text_script, input_variables=['sub_topics', 'context', 'topic', 'previous_section'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_repeated_chain(chain: LLMChain, max_iterations: int = 8, stop_word: str = '[END]', **chain_kwargs) -> str:\n",
    "    \"\"\"\n",
    "    run the podcast chain until the podcast is the stop word is found or the max_iterations is reached\n",
    "\n",
    "    :param chain: the chain to run\n",
    "    :param max_iterations: the maximum number of iterations to run the chain\n",
    "    :param stop_word: the word to stop the chain\n",
    "    :param chain_kwargs: the kwargs to pass to the chain\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    found_end = False\n",
    "    script = ''\n",
    "    while not found_end:\n",
    "        if i >= 6:\n",
    "            print(f'[WARNING] could not finish task in {max_iterations} iterations')\n",
    "            break\n",
    "        output = chain.run(**chain_kwargs)\n",
    "        script += output\n",
    "        if 'previous_section' in chain_kwargs:\n",
    "            chain_kwargs['previous_section'] = output\n",
    "        found_end = stop_word in output\n",
    "        i += 1\n",
    "        print(f'iteration {i} of {max_iterations} finished')\n",
    "\n",
    "    return script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_topics = '\\n'.join(f'  - {sub_topic}' for sub_topic in formatted_topics)\n",
    "sub_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcast_chain = LLMChain(llm=llm, prompt=prompt_template_podcast)\n",
    "\n",
    "podcast_script = run_repeated_chain(podcast_chain, sub_topics=sub_topics, context=wiki_research, topic=topic, previous_section='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write it to a file for later use\n",
    "with open('../out/podcast_script_wiki.txt', 'a') as script_file:\n",
    "    script_file.write(podcast_script)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tools and agents\n",
    "\n",
    "What we could do using other frameworks and manual methods like before (wikipedia), we can now use integrated tools in combination with agents to automate our process further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(['serpapi'], llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = [topic, *formatted_topics]\n",
    "web_research = []\n",
    "\n",
    "for topic in all_topics:\n",
    "    agent_res = agent.run(f\"Task: Do a thorough web research about {topic}. Provide at least 3 sentences of information.\")\n",
    "    web_research.append(agent_res)\n",
    "\n",
    "web_research\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_web_research = '\\n\\n'.join(web_research)\n",
    "formatted_web_research\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcast_chain = LLMChain(llm=llm, prompt=prompt_template_podcast)\n",
    "\n",
    "podcast_script_web = run_repeated_chain(podcast_chain, sub_topics=sub_topics, context=formatted_web_research, topic=topic, previous_section='')\n",
    "podcast_script_web\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../out/podcast_script_web.txt', 'w') as script_file:\n",
    "    script_file.write(podcast_script_web)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo-ki-seminar-p9aLL8gI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
